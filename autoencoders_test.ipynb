{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f1835bd-e615-4303-b17f-834bc899c6e4",
   "metadata": {},
   "source": [
    "# Initial test with denoising autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7182e53-2ba7-4af2-8d75-40384d0bb168",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "import gaiaxpy\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, quantile_transform\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28130f03-e1e0-43b0-9929-e6df77d83ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.RawConfigParser()\n",
    "config.read(\"Config.properties\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8489f6b-aa82-4b12-8592-bb90aeea32c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelengths_path = config.get(\"path_variables\", \"wavelengthspath\")\n",
    "datapath = config.get(\"path_variables\", \"datapath\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e35bda4-9f32-4836-9db8-078c3217f714",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelengths = pd.read_csv(wavelengths_path, header=None).iloc[0].values[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2d16d7-87a1-47da-9425-70f4ac43eec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_files(input_folder):\n",
    "    return [\n",
    "        os.path.join(input_folder, f)\n",
    "        for f in os.listdir(input_folder)\n",
    "        if (os.path.isfile(os.path.join(input_folder, f)) and f.endswith(\".csv\"))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca92c1b-dad3-43dd-b921-b546ee571fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddening_files = get_csv_files(datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82503771-ffe7-4361-941f-e02a565bf668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_sources(files, percentage=0.5, index_col=None):\n",
    "    result_df = pd.DataFrame()\n",
    "    for f in files:\n",
    "        curr_df = pd.read_csv(f)\n",
    "        curr_els = len(curr_df)\n",
    "        random_numbers = random.sample(\n",
    "            range(0, curr_els), int(np.ceil(curr_els * percentage))\n",
    "        )\n",
    "\n",
    "        selected_df = curr_df[curr_df.index.isin(random_numbers)]\n",
    "        if index_col and index_col in selected_df.columns:\n",
    "            selected_df = selected_df.set_index(index_col)\n",
    "        result_df = pd.concat([result_df, selected_df])\n",
    "        break\n",
    "    return selected_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc1ec9f-9c12-4f63-8cfb-c331a56a5f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# files_to_select = [reddening_files[0]]\n",
    "files_to_select = reddening_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca6c362-1a53-4240-8158-2e5b6046bdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = select_sources(files_to_select, percentage=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e688412",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = res_df.dropna()\n",
    "res_df = res_df[~res_df[\"redden_spectra\"].str.contains(\"inf\") == True]\n",
    "res_df = res_df[~res_df[\"original_spectra\"].str.contains(\"inf\") == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89cbe2c-bb14-4e83-88d7-8558db765eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_float_list(input_string):\n",
    "    data = input_string.replace(\"(\", \"\")\n",
    "    data = data.replace(\")\", \"\")\n",
    "    data = data.split(\",\")\n",
    "    return np.array(list(map(float, data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b63c681-c89b-4f71-8467-8486f181bc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gaussian(data, sigma=1):\n",
    "    from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "    gaussian_data = []\n",
    "    smooth_data = []\n",
    "    for spectrum in data:\n",
    "        smooth_spectrum = gaussian_filter1d(spectrum, sigma=sigma)\n",
    "#         result_spectrum = spectrum / smooth_spectrum\n",
    "#         gaussian_data.append(list(result_spectrum))\n",
    "        smooth_data.append(list(smooth_spectrum))\n",
    "    return smooth_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3075aba8-edbf-4dea-9879-eda9d403e7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler(data):\n",
    "    scaled_data = []\n",
    "    for datum in data:\n",
    "        scaled_datum = (datum - min(datum)) / (max(datum) - min(datum))\n",
    "        scaled_data.append(list(scaled_datum))\n",
    "    return scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bc30be-509b-4405-a1f5-67e29832d9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(data_df, normalize=True, save_idx=False, sigma=None):\n",
    "    indexes = data_df.index.tolist()\n",
    "    train_idx, test_idx = train_test_split(indexes)\n",
    "    train_idx.sort()\n",
    "    test_idx.sort()\n",
    "\n",
    "    data_df = data_df.sort_index()\n",
    "    train_data = data_df[data_df.index.isin(train_idx)]\n",
    "    test_data = data_df[data_df.index.isin(test_idx)]\n",
    "\n",
    "    train_noisy_values = train_data[\"redden_spectra\"].to_numpy()\n",
    "    train_noisy_values = np.array([string_to_float_list(x) for x in train_noisy_values])\n",
    "\n",
    "    train_values = train_data[\"original_spectra\"]\n",
    "    train_values = np.array([string_to_float_list(x) for x in train_values])\n",
    "\n",
    "    test_noisy_values = test_data[\"redden_spectra\"]\n",
    "    test_noisy_values = np.array([string_to_float_list(x) for x in test_noisy_values])\n",
    "\n",
    "    test_values = test_data[\"original_spectra\"]\n",
    "    test_values = np.array([string_to_float_list(x) for x in test_values])\n",
    "\n",
    "\n",
    "\n",
    "    if sigma:\n",
    "        print(\"> Smoothing data with sigma={}\".format(sigma))\n",
    "        train_noisy_values = apply_gaussian(train_noisy_values, sigma)\n",
    "        train_values = apply_gaussian(train_values, sigma)\n",
    "        test_noisy_values = apply_gaussian(test_noisy_values, sigma)\n",
    "        test_values = apply_gaussian(test_values, sigma)\n",
    "        \n",
    "    if normalize:\n",
    "        print(\"> Normalizing data\")\n",
    "        train_noisy_values = min_max_scaler(train_noisy_values)\n",
    "        train_values = min_max_scaler(train_values)\n",
    "        test_noisy_values = min_max_scaler(test_noisy_values)\n",
    "        test_values = min_max_scaler(test_values)\n",
    "    if not save_idx:\n",
    "        return train_noisy_values, train_values, test_noisy_values, test_values\n",
    "    return (\n",
    "        train_noisy_values,\n",
    "        train_values,\n",
    "        test_noisy_values,\n",
    "        test_values,\n",
    "        train_idx,\n",
    "        test_idx,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090e0c66-2fe7-49b7-a9cd-576f71094a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_noisy, x_train, x_test_noisy, x_test = split_train_test(res_df, normalize=True)\n",
    "x_train_noisy, x_train, x_test_noisy, x_test, train_idx, test_idx = split_train_test(\n",
    "    res_df, save_idx=True, sigma=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4441afe9-6d31-4a37-bc59-a11346a26f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(Model):\n",
    "    def __init__(self, latent_dim=24):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.encoder = tf.keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(87, activation=\"relu\"),\n",
    "                layers.Dense(32, activation=\"relu\"),\n",
    "                # layers.Dense(24, activation=\"relu\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.decoder = tf.keras.Sequential(\n",
    "            [\n",
    "                # layers.Dense(24, activation=\"relu\"),\n",
    "                layers.Dense(32, activation=\"relu\"),\n",
    "                layers.Dense(87, activation=\"relu\"),                \n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d300e724-f8ab-48bf-b029-62f84aefc251",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Autoencoder()\n",
    "autoencoder.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df53a005-7e84-44cd-941a-e43edfa2e745",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = autoencoder.fit(\n",
    "    x_train_noisy,\n",
    "    x_train,\n",
    "    epochs=25,\n",
    "    shuffle=True,\n",
    "    validation_data=(x_test_noisy, x_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086e9b41-28d6-4f17-b156-31dc304c7cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e0377b-3db9-4bbc-8f7b-f9f76d958c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(result.history[\"loss\"], label=\"Training Loss\")\n",
    "plt.plot(result.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46fa992-2b64-4cbf-bd73-da1937cb2820",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_result = autoencoder.predict(x_test_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf8ab09-c66d-4500-9694-8b9a28c9c8fd",
   "metadata": {},
   "source": [
    "##### Almost identical:\n",
    "* 1236881861774848\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c631b23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_idx =  res_df.loc[test_idx[curr_idx], 'source_id']\n",
    "curr_idx = 134\n",
    "plt.plot(wavelengths, predict_result[curr_idx], label='reconstructed')\n",
    "plt.plot(wavelengths, x_test[curr_idx], label='original')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba549c5e-3389-4264-85fb-8e7be88ab4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "different = 0\n",
    "for i in range(0, len(x_test)):\n",
    "    residual = predict_result[i] - x_test[i]\n",
    "    residual_abs = abs(residual)\n",
    "    if max(residual_abs) >= 0.7:\n",
    "        different = different +1\n",
    "        print(\"Huge difference: {} (id {})\".format(max(residual_abs), test_idx[i]))\n",
    "        plt.plot(predict_result[i], label='reconstructed')\n",
    "        plt.plot(x_test[i], label='original')\n",
    "        plt.plot(x_test_noisy[i], label='noisy')\n",
    "        plt.legend()\n",
    "        plt.plot()\n",
    "        plt.show()\n",
    "print(\"There are {}/{} different elements\".format(different, len(x_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ExtinctionAutoenc",
   "language": "python",
   "name": "extinctionautoenc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
